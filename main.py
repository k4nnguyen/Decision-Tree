import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from saved_model import load_saved_model
from train_decision_tree import train_decision_tree
from crawl import crawl_reviews, chuanHoa
from crawl_batch import crawl_batch
from merge_csvf import merge_all_csv

import joblib

def veBieuDo(df):
    # ƒê·∫£m b·∫£o t·ªìn t·∫°i c·∫£ 2 c·ªôt
    if 'Label' not in df.columns or 'Predicted_Label' not in df.columns:
        print("‚ö†Ô∏è Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì v√¨ thi·∫øu nh√£n th·ª±c ho·∫∑c nh√£n d·ª± ƒëo√°n.")
        return

    # T·∫°o b·∫£ng ƒë·∫øm s·ªë l∆∞·ª£ng theo t·ª´ng l·ªõp
    counts = df.groupby(['Label', 'Predicted_Label']).size().reset_index(name='Count')

    # V·∫Ω bi·ªÉu ƒë·ªì d·∫°ng heatmap
    pivot = counts.pivot(index='Label', columns='Predicted_Label', values='Count').fillna(0)
    sns.heatmap(pivot, annot=True, fmt='g', cmap='Blues')

    plt.title("So s√°nh gi·ªØa Label th·ª±c v√† D·ª± ƒëo√°n")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label") 
    plt.show()

def tinhGiaTri(df):
    # Ki·ªÉm tra c·ªôt t·ªìn t·∫°i
    if 'Label' not in df.columns or 'Predicted_Label' not in df.columns:
        print("‚ö†Ô∏è Thi·∫øu c·ªôt 'Label' ho·∫∑c 'Predicted_Label'.")
        return

    y_true = df['Label']
    y_pred = df['Predicted_Label']

    # Accuracy, Precision, Recall, F1
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)
    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)
    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)

    # In ra b·∫£ng b√°o c√°o classificationa
    print("\nüìä Classification Report:")
    print(classification_report(y_true, y_pred, digits=3))
    print("\n‚úÖ ƒê√°nh gi√° t·ªïng th·ªÉ:")
    print(f"- Accuracy: {accuracy:.3f}")
    print(f"- Precision: {precision:.3f}")
    print(f"- Recall: {recall:.3f}")
    print(f"- F1 Score: {f1:.3f}")

def main():
    predict_store = input("Nh·∫≠p t√™n c·ª≠a h√†ng b·∫°n mu·ªën d·ª± ƒëo√°n b√¨nh lu·∫≠n (V√≠ d·ª•: KFC Ho√†ng Qu·ªëc Vi·ªát): ").strip()
    #crawl_batch()
    merged_path = merge_all_csv()
    train_decision_tree()
    # B∆∞·ªõc 4: T·∫£i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán t·ª´ c·ª≠a h√†ng
    model, vectorizer = load_saved_model()
    if model is None or vectorizer is None:
        print("‚ùå Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh. Qu√° tr√¨nh d·ª´ng l·∫°i.")
        return
    #B∆∞·ªõc 5: C√†o d·ªØ li·ªáu c·ªßa c·ª≠a h√†ng mu·ªën d·ª± ƒëo√°n
    crawl_reviews(predict_store)
    # ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV c·ªßa c·ª≠a h√†ng
    filename = chuanHoa(predict_store) + ".csv"
    filepath = os.path.join("data", filename)
    df = pd.read_csv(filepath)

    # B∆∞·ªõc 5: Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v√† ph√¢n lo·∫°i sentiment cho t·ª´ng review
    reviews = df['Review']
    reviews_vectorized = vectorizer.transform(reviews)
    predictions = model.predict(reviews_vectorized)

    # B∆∞·ªõc 6: Ghi l·∫°i k·∫øt qu·∫£ ph√¢n lo·∫°i v√†o file CSV
    df['Predicted_Label'] = predictions
    output_filepath = os.path.join("result", f"classified_{filename}")
    df.to_csv(output_filepath, index=False, encoding="utf-8")
    tinhGiaTri(df)
    veBieuDo(df)
    print(f"üíæ ƒê√£ ph√¢n lo·∫°i sentiment v√† l∆∞u v√†o file '{output_filepath}' th√†nh c√¥ng!")

if __name__ == "__main__":
    main()
